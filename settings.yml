# At some point this should be generic enough to support multiple VPCs
# and tasks. For demo purposes, we're doing one task of each type and
# adding iteration (even if only for 1) as we go. As such, the base
# infra is a single account and single VPC for now, but trying to keep
# the settings file flexible to avoid too much refactoring later
global: 
  target_vpc: &target_vpc vpc-076e905b3e931d519
  # target_vpc_tag: # future use to query for vpc's that contain a tag
  #   name: serverless_ops
  #   value: true

fargate:
  vpc: *target_vpc

tasks:
  fargate:
    mysql_worker: # the backup/restore task
      name: MySqlWorkerTask
      image_path: "docker/mysql-worker" # place all docker build files here
  lambda:
    mysql_users:
      name: MySqlUsersLambda
      asset_path: "lambda/mysql-users"
      function_code: "app.py"
      entry_point: "handler"

# For production I would NOT store user/pass info in a yml file like this. It is helpful for
# demo purposes as I'm creating Parameter Store values to aid in the walkthrough. 
# See "serverless_ops_tasks.py" for where this is used and thoughts on adjusting.

# parameters: Top level path
#   databases: section for tasks that need db-related info
#     db_name: db name (the database within RDS)
#       env_name: the environment, combined with the db_name this is the unique db combo used for task lookups
parameters:  # The values for tasks to pull from ParameterStore instead of feeding in directly
  databases:
    classicmodels: # key heading, demo code will look for heading/env
      demo:   # calling this demo environment "demo", could be dev, prod, etc.
        db_host: "serverlessops1.cluster-czpi934xq9hf.us-east-1.rds.amazonaws.com"
        db_port: "3306"
        db_name: "classicmodels"
        db_user: "admin"
        db_pass: "Password01"
        s3_bucket: "aws-acd-serverlessops-backups"
        s3_path: "parameterstoretests"